{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18022284",
   "metadata": {},
   "source": [
    "# MPS Annotation Pipeline #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb715dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "from pprintpp import pprint as pp\n",
    "import pipe\n",
    "from datetime import datetime, date\n",
    "\n",
    "load_dotenv() # load .env\n",
    "\n",
    "# load OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95d2db",
   "metadata": {},
   "source": [
    "OntoGPT examples: [here](https://github.com/monarch-initiative/ontogpt/blob/main/notebooks/)\n",
    "\n",
    "OntoGPT templates: [here](https://github.com/monarch-initiative/ontogpt/blob/main/src/ontogpt/templates/)\n",
    "\n",
    "CurateGPT examples: [here](https://github.com/monarch-initiative/curategpt/blob/main/notebooks/command-line/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828d59b",
   "metadata": {},
   "source": [
    "### Pre-Install ###\n",
    "1. Download [CMake](https://cmake.org/download/)\n",
    "2. During installation, check the box to \"Add CMake to system PATH for all users\".\n",
    "3. Download [Visual Studio C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968e1d0",
   "metadata": {},
   "source": [
    "### Install LLM Tools ###\n",
    "\n",
    "OntoGPT is based on Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a novel method to extract ontological content from text or structured data authored by [Caufield et al., 2024](https://doi.org/10.1093/bioinformatics/btae104).\n",
    "\n",
    "CurateGPT is another library that uses LLM embeddings to prioritize semantically similar ontology content to text or structured data input. CurateGPT also enables users to suggest new ontology content and programmatically interact with GitHub issue trackers. Find the preprint for CurateGPT [here](https://doi.org/10.48550/arXiv.2411.00046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ontogpt\n",
    "!pip install curategpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbc65d",
   "metadata": {},
   "source": [
    "### Set OpenAI API Key ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!runoak set-apikey -e openai $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ec8fe",
   "metadata": {},
   "source": [
    "### Show OntoGPT and CurateGPT Options ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curategpt --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9cc39",
   "metadata": {},
   "source": [
    "### Extract Human Phenotype Ontology Terms from MPS Papers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt -vvv extract -i example1.txt -t templates/human_phenotype.yaml -o output/output.yaml --model-provider openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be94670",
   "metadata": {},
   "source": [
    "### Index HPO For AUTO Prefix Terms ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e829a",
   "metadata": {},
   "source": [
    "Behind the scenes, OAK is used to access a variety of different ontologies and allows them to be indexed. See the oaklib docs for documentation on handles such as sqlite:obo:hp.\n",
    "\n",
    "Let's start by making an index of the Human Phenotype Ontology (HP) and the MONDO Disease Ontology (MONDO):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curategpt ontology index -m openai: -c terms_hp sqlite:obo:hp\n",
    "!curategpt ontology index -m openai: -c terms_mondo sqlite:obo:mondo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a8a14",
   "metadata": {},
   "source": [
    "Warning: this currently takes about 2 hrs; if you use OpenAI to embed the terms you will need an OpenAI API key. You can also leave the -m option off and it will use the default chromadb embedding model. gpt-4o is recommended for using CurateGPT.\n",
    "\n",
    "Next, we will determine which terms (prefix AUTO:) could not be matched to HPO by OntoGPT and run a search using OpenAI embeddings for the most similar terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e42c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/output.yaml\", \"r\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# Extract label and attribute it to a MONDO ID\n",
    "label = data[\"extracted_object\"][\"label\"]\n",
    "#!curategpt search -c terms_mondo label\n",
    "\n",
    "# Extract AUTO terms and find semantically similar phenotypes\n",
    "raw_auto_terms = [item for item in data[\"extracted_object\"][\"phenotypes\"] if item.startswith(\"AUTO:\")]\n",
    "auto_terms = [item.replace(\"AUTO:\", \"\").replace(\"%20\", \" \") for item in raw_auto_terms]\n",
    "\n",
    "print(auto_terms)\n",
    "\n",
    "#!curategpt search -c terms_hp auto_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755501f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        filename = f\"article_urls_{timestamp}.json\"\n",
    "        output_path = os.path.join(\"requests//json\", filename)\n",
    "\n",
    "        # save json\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curategpt ask -c phenopackets_384 \"what genes are associated with renal phenotypes?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50ae6d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
